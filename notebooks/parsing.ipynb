{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import muspy\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = muspy.load(\"../data/example.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_resolution_threshold(mus, threshold=100):\n",
    "    \"\"\"Return the nearest even MusPy resolution needed to consider notes 'threshold' milliseconds apart as different (but no lower).\"\"\"\n",
    "    return [round(((x.qpm / 60) ** -1 * 1000 / threshold) / 2) * 2 for x in mus.tempos]\n",
    "\n",
    "def parse_input(true_data, path, threshold=100, resolution=None):\n",
    "    \"\"\"Parse a .txt file output from the follow.js API into a MusPy object.\"\"\"\n",
    "    'TODO: Add support for multiple tempos'\n",
    "    with open(path) as f:\n",
    "        raw_data = f.readlines()[1:]\n",
    "\n",
    "    raw_data = np.array([[float(y) for y in x.strip(\"\\n|,\").split(\",\")] for x in raw_data]) # raw_data is now a list of (time, pitch, velocity) tuples\n",
    "    parsed_data = np.zeros((raw_data.shape[0] // 2, 4))\n",
    "    countoff_offset = true_data.time_signatures[0].numerator * (true_data.tempos[0].qpm / 60) ** -1 # time offset in milliseconds to account for countoff\n",
    "\n",
    "    raw_res = get_resolution_threshold(true_data, threshold)[0]\n",
    "    if resolution is not None:\n",
    "        raw_res = resolution\n",
    "    time2beats = lambda x: round(x * true_data.tempos[0].qpm * raw_res / 60)\n",
    "    for i in np.arange(0, raw_data.shape[0], 2):\n",
    "        parsed_data[i // 2] = np.array(\n",
    "            [\n",
    "                time2beats(raw_data[i][0] / 1000 - countoff_offset), # time in new resolution\n",
    "                raw_data[i][1], # MIDI pitch\n",
    "                time2beats((raw_data[i+1][0] - raw_data[i][0]) / 1000), # duration in new resolution\n",
    "                raw_data[i][2] # velocity\n",
    "            ],\n",
    "        dtype=int)\n",
    "    input_mus = muspy.from_note_representation(parsed_data.astype(int), resolution=raw_res)\n",
    "    return input_mus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_output(true_path, out_path, threshold=100, resolution=None):\n",
    "    \"\"\"Clean a .txt file output from the follow.js API into a MusPy object.\"\"\"\n",
    "    if true_path.endswith(\".json\"):\n",
    "        true_mus = muspy.load(true_path)\n",
    "    elif true_path.endswith(\".xml\"):\n",
    "        true_mus = muspy.read_musicxml(true_path)\n",
    "    elif true_path.endswith(\".abc\"):\n",
    "        true_mus = muspy.read_abc(true_path)\n",
    "    else:\n",
    "        raise NotImplementedError(\"File type not supported.\")\n",
    "    \n",
    "    if type(true_mus) == list:\n",
    "        true_mus = true_mus[0]\n",
    "    input_mus = parse_input(true_mus, out_path, threshold, resolution)\n",
    "    finest_rhythm = round(sorted(np.unique((true_mus.to_note_representation()[:, 0] / true_mus.resolution) % 1))[1] ** -1) # the finest rhythm in the piece\n",
    "    true_mus.adjust_resolution(target=math.lcm(input_mus.resolution, finest_rhythm))\n",
    "    input_mus.adjust_resolution(target=math.lcm(input_mus.resolution, finest_rhythm))\n",
    "    input_mus.barlines = true_mus.barlines\n",
    "    input_mus.time_signatures = true_mus.time_signatures\n",
    "    bartimes = np.array([x.time for x in input_mus.barlines])\n",
    "    bartime2n = {x: i for i,x in enumerate(bartimes)}\n",
    "    for i, note in enumerate(input_mus.tracks[0].notes):\n",
    "        note.label = int(\n",
    "            note.time in true_mus.to_note_representation()[:,0] and note.pitch == true_mus.to_note_representation()[np.where(note.time == true_mus.to_note_representation()[:, 0]),1] # Label is 1 if the note is correct at resolution\n",
    "        )\n",
    "   \n",
    "        note.bar_n = bartime2n[bartimes[bartimes <= note.time].max()] # Label with 0-indexed bar number\n",
    "        if note.label == 1:\n",
    "            print(note, note.label, note.bar_n)\n",
    "    return input_mus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note(time=0, pitch=60, duration=0, velocity=113) 1 0\n",
      "Note(time=3, pitch=62, duration=0, velocity=89) 1 0\n",
      "Note(time=4, pitch=64, duration=0, velocity=103) 1 1\n",
      "Note(time=5, pitch=62, duration=0, velocity=84) 1 1\n",
      "Note(time=6, pitch=60, duration=0, velocity=87) 1 1\n",
      "Note(time=8, pitch=60, duration=0, velocity=91) 1 2\n",
      "Note(time=10, pitch=58, duration=1, velocity=73) 1 2\n",
      "Note(time=12, pitch=57, duration=2, velocity=82) 1 3\n",
      "Note(time=16, pitch=62, duration=1, velocity=80) 1 4\n",
      "Note(time=18, pitch=58, duration=1, velocity=50) 1 4\n",
      "Note(time=19, pitch=57, duration=0, velocity=66) 1 4\n",
      "Note(time=20, pitch=55, duration=3, velocity=69) 1 5\n",
      "Note(time=24, pitch=62, duration=1, velocity=81) 1 6\n",
      "Note(time=26, pitch=64, duration=1, velocity=87) 1 6\n",
      "Note(time=30, pitch=60, duration=0, velocity=64) 1 7\n",
      "Note(time=30, pitch=60, duration=1, velocity=91) 1 7\n",
      "Note(time=42, pitch=64, duration=0, velocity=76) 1 10\n",
      "Note(time=48, pitch=64, duration=0, velocity=88) 1 12\n",
      "Note(time=51, pitch=60, duration=0, velocity=87) 1 12\n",
      "Note(time=78, pitch=60, duration=0, velocity=97) 1 19\n",
      "Note(time=80, pitch=64, duration=0, velocity=79) 1 20\n",
      "Note(time=99, pitch=60, duration=0, velocity=88) 1 24\n",
      "Note(time=104, pitch=62, duration=0, velocity=102) 1 26\n",
      "Note(time=105, pitch=60, duration=1, velocity=101) 1 26\n",
      "Note(time=122, pitch=62, duration=0, velocity=53) 1 30\n",
      "Note(time=122, pitch=62, duration=0, velocity=64) 1 30\n"
     ]
    }
   ],
   "source": [
    "x =clean_output(\"/Users/znovack/opt/miniconda3/envs/music/lib/python3.9/site-packages/music21/corpus/ciconia/quod_jactatur.xml\", '/Users/znovack/Downloads/inputs/quod_jactatur_output (2).txt', resolution=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TimeSignature(time=0, numerator=2, denominator=4)]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.time_signatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
