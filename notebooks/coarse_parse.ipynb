{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import muspy\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from pathlib import PosixPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_local_mscz(raw_path, dpath='/data2/zachary/musescore/data'):\n",
    "    clean_path = raw_path.split(\"/\")[-1] + '.mscz'\n",
    "    for dirpath, dirnames, filenames in os.walk(dpath):\n",
    "        if not dirnames:\n",
    "            if clean_path in filenames:\n",
    "                return os.path.join(dirpath, clean_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath_df = pd.read_csv('/data2/zachary/musescore/mscz-files.csv')\n",
    "fpath_df.set_index('id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = []\n",
    "for dirpath, dirnames, filenames in os.walk('/data2/zachary/musescore/data'):\n",
    "    if not dirnames:\n",
    "        all_files += list(map(lambda x: os.path.join(dirpath, x), filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = {x.split(\"/\")[-1]: x for x in all_files}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath_df['ref2'] = fpath_df.ref.apply(lambda x: x.split(\"/\")[-1] + '.mscz')\n",
    "fpath_df['loc_exist'] = fpath_df.ref2.apply(lambda x: x in all_files)\n",
    "fpath_df = fpath_df[fpath_df['loc_exist'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath_df['ref3'] = fpath_df.ref2.apply(lambda x: all_files[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirpath = '/data2/zachary/musescore/metadata'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "compls = []\n",
    "for fpath in os.listdir(dirpath):\n",
    "    if fpath.isnumeric():\n",
    "        subdir = os.path.join(dirpath, fpath)\n",
    "        for subpath in os.listdir(subdir):\n",
    "            with open(subdir + '/' + subpath, 'r') as f:\n",
    "                try:\n",
    "                    d = json.load(f)\n",
    "                    compls.append({'path': subdir + '/' + subpath, 'd': d})\n",
    "                except:\n",
    "                    print(subdir + '/' + subpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dur2Num(dur):\n",
    "    ms = dur.split(\":\")\n",
    "    if len(ms) == 1:\n",
    "        return int(ms[0])\n",
    "    return int(ms[0]) * 60 + int(ms[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pianos = list(filter(lambda x: 'piano' in [y.lower() for y in x['d']['data']['score']['parts_names']] and len(x['d']['data']['score']['parts_names']) == 1 and len(x['d']) and dur2Num(x['d']['data']['score']['duration']) > 20, compls))\n",
    "pianos = list(filter(lambda x: x['d']['data']['score']['id'] in fpath_df.index, pianos))\n",
    "nans = list(filter(lambda x: x['d']['data']['score']['complexity'] == 0, pianos))\n",
    "easy = list(filter(lambda x: x['d']['data']['score']['complexity'] == 1, pianos))\n",
    "med = list(filter(lambda x: x['d']['data']['score']['complexity'] == 2, pianos))\n",
    "hard = list(filter(lambda x: x['d']['data']['score']['complexity'] == 3, pianos))\n",
    "np.random.seed(42)\n",
    "easy_eq = np.random.choice(easy, 4400)\n",
    "med_eq = np.random.choice(med, 4400)\n",
    "hard_eq = np.random.choice(hard, 4400)\n",
    "train_ds = np.concatenate([easy_eq[:int(4400*0.8)], med_eq[:int(4400*0.8)], hard_eq[:int(4400*0.8)]])\n",
    "val_ds = np.concatenate([easy_eq[int(4400*0.8):int(4400*0.8) + int(4400*0.1)], med_eq[int(4400*0.8):int(4400*0.8) + int(4400*0.1)], hard_eq[int(4400*0.8):int(4400*0.8) + int(4400*0.1)]])\n",
    "test_ds = np.concatenate([easy_eq[int(4400*0.8) + int(4400*0.1):], med_eq[int(4400*0.8) + int(4400*0.1):], hard_eq[int(4400*0.8) + int(4400*0.1):]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = []\n",
    "for piece in easy_eq:\n",
    "    tcode = piece['d']['data']['score']['duration']\n",
    "    if len(tcode.split(\":\")) == 2:\n",
    "        times.append(int(tcode.split(\":\")[0]) * 60 + int(tcode.split(\":\")[1]))\n",
    "    else:\n",
    "        times.append(int(tcode.split(\":\")[0]))\n",
    "for piece in med_eq:\n",
    "    tcode = piece['d']['data']['score']['duration']\n",
    "    if len(tcode.split(\":\")) == 2:\n",
    "        times.append(int(tcode.split(\":\")[0]) * 60 + int(tcode.split(\":\")[1]))\n",
    "    else:\n",
    "        times.append(int(tcode.split(\":\")[0]))\n",
    "for piece in hard_eq:\n",
    "    tcode = piece['d']['data']['score']['duration']\n",
    "    if len(tcode.split(\":\")) == 2:\n",
    "        times.append(int(tcode.split(\":\")[0]) * 60 + int(tcode.split(\":\")[1]))\n",
    "    else:\n",
    "        times.append(int(tcode.split(\":\")[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "770.6694444444445"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(times) / 3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 612.1686111111111\n",
      "val time: 79.02111111111111\n",
      "test time: 79.47972222222222\n"
     ]
    }
   ],
   "source": [
    "times = []\n",
    "for piece in train_ds:\n",
    "    tcode = piece['d']['data']['score']['duration']\n",
    "    if len(tcode.split(\":\")) == 2:\n",
    "        times.append(int(tcode.split(\":\")[0]) * 60 + int(tcode.split(\":\")[1]))\n",
    "    else:\n",
    "        times.append(int(tcode.split(\":\")[0]))\n",
    "print(\"train time:\", sum(times) / 3600)\n",
    "\n",
    "times = []\n",
    "for piece in val_ds:\n",
    "    tcode = piece['d']['data']['score']['duration']\n",
    "    if len(tcode.split(\":\")) == 2:\n",
    "        times.append(int(tcode.split(\":\")[0]) * 60 + int(tcode.split(\":\")[1]))\n",
    "    else:\n",
    "        times.append(int(tcode.split(\":\")[0]))\n",
    "print(\"val time:\", sum(times) / 3600)\n",
    "\n",
    "times = []\n",
    "for piece in test_ds:\n",
    "    tcode = piece['d']['data']['score']['duration']\n",
    "    if len(tcode.split(\":\")) == 2:\n",
    "        times.append(int(tcode.split(\":\")[0]) * 60 + int(tcode.split(\":\")[1]))\n",
    "    else:\n",
    "        times.append(int(tcode.split(\":\")[0]))\n",
    "print(\"test time:\", sum(times) / 3600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, d in enumerate(train_ds):\n",
    "    raw_path = fpath_df.loc[d['d']['data']['score']['id']]['ref3']\n",
    "    if type(raw_path) == pd.Series:\n",
    "        raw_path = raw_path.iloc[0]\n",
    "    d['mscz_path'] = raw_path\n",
    "    train_ds[i] = d\n",
    "for i, d in enumerate(val_ds):\n",
    "    raw_path = fpath_df.loc[d['d']['data']['score']['id']]['ref3']\n",
    "    if type(raw_path) == pd.Series:\n",
    "        raw_path = raw_path.iloc[0]\n",
    "    d['mscz_path'] = raw_path\n",
    "    val_ds[i] = d\n",
    "for i, d in enumerate(test_ds):\n",
    "    raw_path = fpath_df.loc[d['d']['data']['score']['id']]['ref3']\n",
    "    if type(raw_path) == pd.Series:\n",
    "        raw_path = raw_path.iloc[0]\n",
    "    d['mscz_path'] = raw_path\n",
    "    test_ds[i] = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_train_ds = {d['d']['data']['score']['id']: d for d in train_ds}\n",
    "with open('../data/train_metadata.json', 'w') as f:\n",
    "    json.dump(id_train_ds, f, indent=2)\n",
    "id_val_ds = {d['d']['data']['score']['id']: d for d in val_ds}\n",
    "with open('../data/val_metadata.json', 'w') as f:\n",
    "    json.dump(id_val_ds, f, indent=2)\n",
    "id_test_ds = {d['d']['data']['score']['id']: d for d in test_ds}\n",
    "with open('../data/test_metadata.json', 'w') as f:\n",
    "    json.dump(id_test_ds, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/train_metadata.json', 'r') as f:\n",
    "    id_train_ds = json.load(f)\n",
    "with open('../data/val_metadata.json', 'r') as f:\n",
    "    id_val_ds = json.load(f)\n",
    "with open('../data/test_metadata.json', 'r') as f:\n",
    "    id_test_ds = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(\"mkdir /data2/zachary/musescore/coarse_data/train/\")\n",
    "os.system(\"mkdir /data2/zachary/musescore/coarse_data/val/\")\n",
    "os.system(\"mkdir /data2/zachary/musescore/coarse_data/test/\")\n",
    "for idx, d in id_train_ds.items():\n",
    "    os.system(f\"cp {d['mscz_path']} /data2/zachary/musescore/coarse_data/train/\")\n",
    "for idx, d in id_val_ds.items():\n",
    "    os.system(f\"cp {d['mscz_path']} /data2/zachary/musescore/coarse_data/val/\")\n",
    "for idx, d in id_test_ds.items():\n",
    "    os.system(f\"cp {d['mscz_path']} /data2/zachary/musescore/coarse_data/test/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zachary/miniconda3/envs/music/lib/python3.9/site-packages/muspy/inputs/musescore.py:962: MuseScoreWarning: Detected a legacy MuseScore version of 2.06. Data might not be loaded correctly.\n",
      "  warnings.warn(\n",
      "/home/zachary/miniconda3/envs/music/lib/python3.9/site-packages/muspy/inputs/musescore.py:962: MuseScoreWarning: Detected a legacy MuseScore version of 1.14. Data might not be loaded correctly.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for f in os.listdir('/data2/zachary/musescore/coarse_data/train/'):\n",
    "    try:\n",
    "        x = muspy.read_musescore(os.path.join('/data2/zachary/musescore/coarse_data/train/', f))\n",
    "        if len(x.tracks[0]) < 10:\n",
    "            os.system(f\"rm /data2/zachary/musescore/coarse_data/train/{f}\")\n",
    "    except:\n",
    "        os.system(f\"rm /data2/zachary/musescore/coarse_data/train/{f}\")\n",
    "for f in os.listdir('/data2/zachary/musescore/coarse_data/val/'):\n",
    "    try:\n",
    "        x = muspy.read_musescore(os.path.join('/data2/zachary/musescore/coarse_data/val/', f))\n",
    "        if len(x.tracks[0]) < 10:\n",
    "            os.system(f\"rm /data2/zachary/musescore/coarse_data/val/{f}\")\n",
    "    except:\n",
    "        os.system(f\"rm /data2/zachary/musescore/coarse_data/val/{f}\")\n",
    "for f in os.listdir('/data2/zachary/musescore/coarse_data/test/'):\n",
    "    try:\n",
    "        x = muspy.read_musescore(os.path.join('/data2/zachary/musescore/coarse_data/test/', f))\n",
    "        if len(x.tracks[0]) < 10:\n",
    "            os.system(f\"rm /data2/zachary/musescore/coarse_data/test/{f}\")\n",
    "    except:\n",
    "        os.system(f\"rm /data2/zachary/musescore/coarse_data/test/{f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocalMuseScoreDataset(muspy.FolderDataset):\n",
    "\n",
    "    _extension = 'mscz'\n",
    "    _info = muspy.DatasetInfo(\"MuseScore Dataset\")\n",
    "    \n",
    "\n",
    "    def read(self, filename) -> muspy.Music:\n",
    "        \"\"\"Read a file into a Music object.\"\"\"\n",
    "        obj = muspy.read_musescore(filename)\n",
    "        return obj\n",
    "    \n",
    "    def to_pytorch_dataset(\n",
    "        self,\n",
    "        factory=None,\n",
    "        representation: str = None,\n",
    "        split_filename=None,\n",
    "        splits=None,\n",
    "        random_state=None,\n",
    "        labpath=None,\n",
    "        **kwargs):\n",
    "        \"\"\"Return the dataset as a PyTorch dataset.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        factory : Callable, optional\n",
    "            Function to be applied to the Music objects. The input is a\n",
    "            Music object, and the output is an array or a tensor.\n",
    "        representation : str, optional\n",
    "            Target representation. See :func:`muspy.to_representation()`\n",
    "            for available representation.\n",
    "        split_filename : str or Path, optional\n",
    "            If given and exists, path to the file to read the split\n",
    "            from. If None or not exists, path to save the split.\n",
    "        splits : float or list of float, optional\n",
    "            Ratios for train-test-validation splits. If None, return the\n",
    "            full dataset as a whole. If float, return train and test\n",
    "            splits. If list of two floats, return train and test splits.\n",
    "            If list of three floats, return train, test and validation\n",
    "            splits.\n",
    "        random_state : int, array_like or RandomState, optional\n",
    "            Random state used to create the splits. If int or\n",
    "            array_like, the value is passed to\n",
    "            :class:`numpy.random.RandomState`, and the created\n",
    "            RandomState object is used to create the splits. If\n",
    "            RandomState, it will be used to create the splits.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        :class:torch.utils.data.Dataset` or Dict of \\\n",
    "                :class:torch.utils.data.Dataset`\n",
    "            Converted PyTorch dataset(s).\n",
    "\n",
    "        \"\"\"\n",
    "        if representation is None and factory is None:\n",
    "            raise TypeError(\n",
    "                \"One of `representation` and `factory` must be given.\"\n",
    "            )\n",
    "        if representation is not None and factory is not None:\n",
    "            raise TypeError(\n",
    "                \"Only one of `representation` and `factory` can be given.\"\n",
    "            )\n",
    "\n",
    "        try:\n",
    "            # pylint: disable=import-outside-toplevel\n",
    "            from torch.utils.data import Dataset as TorchDataset\n",
    "        except ImportError as err:\n",
    "            raise ImportError(\"Optional package pytorch is required.\") from err\n",
    "\n",
    "        class TorchMusicFactoryDataset(TorchDataset):\n",
    "            \"\"\"A PyTorch dataset built from a Music dataset.\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "            dataset : :class:`muspy.Dataset`\n",
    "                Dataset object to base on.\n",
    "            factory : Callable\n",
    "                Function to be applied to the Music objects. The input is a\n",
    "                Music object, and the output is an array or a tensor.\n",
    "\n",
    "            \"\"\"\n",
    "\n",
    "            def __init__(\n",
    "                self,\n",
    "                dataset,\n",
    "                factory,\n",
    "                labpath,\n",
    "                subset: str = \"Full\",\n",
    "                indices=None,\n",
    "            ):\n",
    "                self.dataset = dataset\n",
    "                self.factory = factory\n",
    "                self.subset = subset\n",
    "                self.indices = indices\n",
    "                self.dataset.on_the_fly()\n",
    "        \n",
    "                with open(labpath, 'r') as f:\n",
    "                    set_files = set(self.dataset._filenames)\n",
    "                    self.metadata = json.load(f)\n",
    "                    self.metadata = {k: v for k,v in list(filter(lambda x: PosixPath(os.path.join(self.dataset.root, x[1]['mscz_path'].split(\"/\")[-1])) in set_files, self.metadata.items()))}\n",
    "                    self.metadata = {PosixPath(os.path.join(self.dataset.root, d['mscz_path'].split(\"/\")[-1])): d for d in self.metadata.values()}\n",
    "                    self.labels = {k: v['d']['data']['score']['complexity'] for k,v in self.metadata.items()}\n",
    "                    self.labels = [x[1] for x in sorted(self.labels.items(), key=lambda y: self.dataset._filenames.index(y[0]))]\n",
    "                self.dataset.use_converted()\n",
    "                    \n",
    "                if self.indices is not None:\n",
    "                    self.indices = sorted(\n",
    "                        idx for idx in self.indices if idx < len(self.dataset)\n",
    "                    )\n",
    "\n",
    "            def __repr__(self) -> str:\n",
    "                return (\n",
    "                    f\"TorchMusicFactoryDataset(dataset={self.dataset}, \"\n",
    "                    f\"factory={self.subset}, subset={self.factory})\"\n",
    "                )\n",
    "\n",
    "            def __getitem__(self, index):\n",
    "                if self.indices is None:\n",
    "                    return self.factory(self.dataset[index]), self.labels[index]\n",
    "                return self.factory(self.dataset[self.indices[index]]), self.labels[self.indices[index]]\n",
    "\n",
    "            def __len__(self) -> int:\n",
    "                if self.indices is None:\n",
    "                    return len(self.dataset)\n",
    "                return len(self.indices)\n",
    "\n",
    "        class TorchRepresentationDataset(TorchMusicFactoryDataset):\n",
    "            \"\"\"A PyTorch music dataset.\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "            dataset : :class:`muspy.Dataset`\n",
    "                Dataset object to base on.\n",
    "            representation : str\n",
    "                Target representation. See\n",
    "                :func:`muspy.to_representation()` for available\n",
    "                representation.\n",
    "\n",
    "            \"\"\"\n",
    "\n",
    "            def __init__(\n",
    "                self,\n",
    "                dataset,\n",
    "                labpath,\n",
    "                representation: str,\n",
    "                subset=\"Full\",\n",
    "                indices=None,\n",
    "                **kwargs,\n",
    "            ):\n",
    "                self.representation = representation\n",
    "\n",
    "                def factory(music):\n",
    "                    return music.to_representation(representation, **kwargs)\n",
    "\n",
    "                super().__init__(\n",
    "                    dataset, labpath=labpath, factory=factory, subset=subset, indices=indices\n",
    "                )\n",
    "\n",
    "            def __repr__(self) -> str:\n",
    "                return (\n",
    "                    f\"TorchRepresentationDataset(dataset={self.dataset}, \"\n",
    "                    f\"representation={self.representation}, \"\n",
    "                    f\"subset={self.subset})\"\n",
    "                )\n",
    "\n",
    "        # No split\n",
    "        if splits is None:\n",
    "            if representation is not None:\n",
    "                return TorchRepresentationDataset(\n",
    "                    self,labpath, representation, **kwargs\n",
    "                )\n",
    "            return TorchMusicFactoryDataset(self, factory, labpath=labpath)  # type: ignore\n",
    "\n",
    "        datasets= {}\n",
    "        indices_list = self.split(split_filename, splits, random_state)\n",
    "        for key, value in indices_list.items():\n",
    "            if representation is not None:\n",
    "                datasets[key] = TorchRepresentationDataset(\n",
    "                    self, representation, key, value, **kwargs\n",
    "                )\n",
    "            else:\n",
    "\n",
    "                datasets[key] = TorchMusicFactoryDataset(\n",
    "                    self, factory, key, value  # type: ignore\n",
    "                )\n",
    "\n",
    "        return datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = LocalMuseScoreDataset('/data2/zachary/musescore/coarse_data/train/')\n",
    "trainDataset = train.to_pytorch_dataset(representation='event', labpath='../data/train_metadata.json')\n",
    "val = LocalMuseScoreDataset('/data2/zachary/musescore/coarse_data/val/')\n",
    "valDataset = val.to_pytorch_dataset(representation='event', labpath='../data/val_metadata.json')\n",
    "test = LocalMuseScoreDataset('/data2/zachary/musescore/coarse_data/test/')\n",
    "testDataset = test.to_pytorch_dataset(representation='event', labpath='../data/test_metadata.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(trainDataset)\n",
    "val_dataloader = DataLoader(valDataset)\n",
    "test_dataloader = DataLoader(testDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('music')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9af94f28876c9d3667e32c3f57cf369bad4902fd5c407457529a66e9442bcdc6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
